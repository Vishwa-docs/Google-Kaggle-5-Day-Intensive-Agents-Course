{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:44:15.776708Z","iopub.execute_input":"2025-11-13T20:44:15.776907Z","iopub.status.idle":"2025-11-13T20:44:15.781124Z","shell.execute_reply.started":"2025-11-13T20:44:15.776889Z","shell.execute_reply":"2025-11-13T20:44:15.780376Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:45:00.726346Z","iopub.execute_input":"2025-11-13T20:45:00.726615Z","iopub.status.idle":"2025-11-13T20:45:00.982065Z","shell.execute_reply.started":"2025-11-13T20:45:00.726594Z","shell.execute_reply":"2025-11-13T20:45:00.981345Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:45:04.487492Z","iopub.execute_input":"2025-11-13T20:45:04.487872Z","iopub.status.idle":"2025-11-13T20:45:39.514689Z","shell.execute_reply.started":"2025-11-13T20:45:04.487846Z","shell.execute_reply":"2025-11-13T20:45:39.513696Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:45:47.889745Z","iopub.execute_input":"2025-11-13T20:45:47.890032Z","iopub.status.idle":"2025-11-13T20:45:47.894065Z","shell.execute_reply.started":"2025-11-13T20:45:47.890010Z","shell.execute_reply":"2025-11-13T20:45:47.893408Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:00.095171Z","iopub.execute_input":"2025-11-13T20:46:00.095446Z","iopub.status.idle":"2025-11-13T20:46:00.100627Z","shell.execute_reply.started":"2025-11-13T20:46:00.095427Z","shell.execute_reply":"2025-11-13T20:46:00.100041Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:02.758738Z","iopub.execute_input":"2025-11-13T20:46:02.759063Z","iopub.status.idle":"2025-11-13T20:46:02.763935Z","shell.execute_reply.started":"2025-11-13T20:46:02.759035Z","shell.execute_reply":"2025-11-13T20:46:02.763319Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:06.732832Z","iopub.execute_input":"2025-11-13T20:46:06.733111Z","iopub.status.idle":"2025-11-13T20:46:06.739225Z","shell.execute_reply.started":"2025-11-13T20:46:06.733093Z","shell.execute_reply":"2025-11-13T20:46:06.737509Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:13.172536Z","iopub.execute_input":"2025-11-13T20:46:13.172797Z","iopub.status.idle":"2025-11-13T20:46:21.594478Z","shell.execute_reply.started":"2025-11-13T20:46:13.172778Z","shell.execute_reply":"2025-11-13T20:46:21.593783Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are poised to revolutionize AI by offering unprecedented computational power. Quantum computers, using qubits, can process vast amounts of data simultaneously, drastically speeding up AI model training, improving optimization, and enabling AI to solve problems currently beyond classical computing's reach, such as in drug discovery and materials science.\n\nKey developments include progress in quantum error correction, with prototypes like Google's logical qubit demonstrating reduced errors, and the creation of more powerful quantum processors, such as IBM's Nighthawk, aiming for \\\"quantum advantage\\\" where quantum computers outperform classical ones.\n\nThe synergy between quantum computing and AI, termed \\\"Quantum AI,\\\" promises more sustainable AI solutions with lower energy consumption. Potential applications are diverse, including personalized medicine, accelerated drug discovery, optimized logistics, financial risk assessment, and new renewable energy technologies. Hybrid approaches combining quantum and classical computing are also advancing.\n\nHowever, it's noted that quantum computing might not benefit all AI applications universally, particularly those reliant on massive datasets where input/output speeds could be a bottleneck. Despite these considerations, ongoing breakthroughs suggest a future where Quantum AI plays a significant, transformative role across many industries.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:30.125829Z","iopub.execute_input":"2025-11-13T20:46:30.126685Z","iopub.status.idle":"2025-11-13T20:46:30.131016Z","shell.execute_reply.started":"2025-11-13T20:46:30.126660Z","shell.execute_reply":"2025-11-13T20:46:30.130220Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:32.868700Z","iopub.execute_input":"2025-11-13T20:46:32.869222Z","iopub.status.idle":"2025-11-13T20:46:32.873568Z","shell.execute_reply.started":"2025-11-13T20:46:32.869206Z","shell.execute_reply":"2025-11-13T20:46:32.872932Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:35.174806Z","iopub.execute_input":"2025-11-13T20:46:35.175129Z","iopub.status.idle":"2025-11-13T20:46:35.180112Z","shell.execute_reply.started":"2025-11-13T20:46:35.175107Z","shell.execute_reply":"2025-11-13T20:46:35.179309Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:46.054736Z","iopub.execute_input":"2025-11-13T20:46:46.054996Z","iopub.status.idle":"2025-11-13T20:46:46.059379Z","shell.execute_reply.started":"2025-11-13T20:46:46.054980Z","shell.execute_reply":"2025-11-13T20:46:46.058494Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:46:49.439834Z","iopub.execute_input":"2025-11-13T20:46:49.440306Z","iopub.status.idle":"2025-11-13T20:46:58.153883Z","shell.execute_reply.started":"2025-11-13T20:46:49.440279Z","shell.execute_reply":"2025-11-13T20:46:58.153272Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > ## Multi-Agent Systems: Your Secret Weapon for Smarter Software Development\n\nAre you tired of monolithic codebases that are a nightmare to maintain? Do you dream of building software that can adapt, learn, and collaborate to solve complex problems? Then it's time to unlock the power of Multi-Agent Systems (MAS)! Forget the days of single, all-knowing programs; the future of software development lies in the intelligent interaction of multiple autonomous agents.\n\nHere's how embracing MAS can revolutionize your development workflow and the software you create:\n\n### 1. Enhanced Modularity and Maintainability: Building Blocks for Success\n\n*   **Decomposition Made Easy:** MAS naturally encourages breaking down complex problems into smaller, independent, and manageable agent modules. This means cleaner code, easier debugging, and faster feature development.\n*   **Reduced Interdependencies:** Each agent can be developed and tested in isolation, minimizing the ripple effect of changes. This significantly reduces the risk of introducing bugs and speeds up the overall development lifecycle.\n*   **Scalability by Design:** Adding new functionalities often means introducing new agents or enhancing existing ones without overhauling the entire system. This makes your software inherently more scalable and adaptable to future demands.\n\n### 2. Dynamic Problem Solving and Adaptability: Software That Thinks\n\n*   **Intelligent Collaboration:** Agents can communicate, negotiate, and coordinate their actions to achieve a common goal. This enables them to tackle problems that are too complex for a single program to handle effectively.\n*   **Autonomous Decision-Making:** Each agent possesses its own goals and can make decisions based on its local knowledge and perception of the environment. This leads to more resilient and responsive systems.\n*   **Learning and Evolution:** MAS can be designed to learn from experience and adapt their behavior over time. This allows your software to evolve and improve its performance without constant manual intervention.\n\n### 3. Robustness and Resilience: Systems That Bounce Back\n\n*   **Fault Tolerance:** If one agent fails, the system doesn't necessarily collapse. Other agents can potentially compensate for the failed agent's role or the system can gracefully degrade, ensuring continued operation.\n*   **Distributed Intelligence:** Spreading the workload and decision-making across multiple agents makes the system less vulnerable to single points of failure. This is crucial for critical applications where downtime is unacceptable.\n*   **Self-Healing Capabilities:** Advanced MAS can be programmed to detect and even repair issues within the system, further enhancing its reliability and reducing the need for human oversight.\n\n### Conclusion: Embrace the Agent Revolution\n\nMulti-Agent Systems aren't just a theoretical concept; they are a powerful paradigm shift for software developers. By embracing MAS, you can build more modular, intelligent, and robust software solutions that are easier to develop, maintain, and scale. So, are you ready to empower your code with the intelligence of multiple agents and build the next generation of smart applications? The future of software is collaborative, and it's time you joined the agent revolution.\nWriterAgent > ## Unlock Smarter Software: It's Time for Multi-Agent Systems!\n\nAre you bogged down by monolithic codebases? Do you yearn for software that's not just functional, but truly intelligent and adaptive? Then let me, WriterAgent, introduce you to your new secret weapon: **Multi-Agent Systems (MAS)**. Forget single, all-powerful programs; the future is about collaboration and distributed intelligence.\n\nMAS offers a revolutionary approach to software development, starting with **enhanced modularity and maintainability**. Imagine breaking down complex challenges into smaller, independent agent modules. This means cleaner code, easier debugging, and significantly reduced interdependencies. Your features become faster to develop, and scalability is no longer a headache ‚Äì just add more agents!\n\nBut the benefits don't stop there. MAS empowers your software with **dynamic problem-solving and adaptability**. Agents can communicate, negotiate, and coordinate, tackling problems that would overwhelm a single entity. Each agent makes autonomous decisions, leading to more resilient and responsive systems. Plus, MAS can learn and evolve, improving performance over time without constant manual tweaks.\n\nFinally, consider **robustness and resilience**. If one agent falters, the system doesn't collapse. Other agents can step in, or the system can gracefully degrade, ensuring continuous operation. This distributed intelligence minimizes single points of failure, a critical advantage for any application where downtime is not an option.\n\nEmbracing MAS means building software that is more modular, intelligent, and robust. Ready to empower your code with the power of collaboration? The agent revolution is here!\nEditorAgent > ## Multi-Agent Systems: Your Secret Weapon for Smarter Software Development\n\nAre you tired of monolithic codebases that feel like a tangled mess to maintain? Do you dream of building software that can truly adapt, learn, and collaborate to solve complex problems? Then it's time to unlock the power of **Multi-Agent Systems (MAS)**! Forget the days of single, all-knowing programs; the future of software development lies in the intelligent interaction of multiple autonomous agents working together.\n\nEmbracing MAS can fundamentally revolutionize both your development workflow and the software you create. Here‚Äôs how:\n\n### 1. Enhanced Modularity and Maintainability: Building Blocks for Success\n\nMAS naturally encourages a **decomposition-first approach**. Complex challenges are broken down into smaller, independent, and thus more manageable agent modules. This translates directly into:\n\n*   **Cleaner Code:** Smaller, focused modules are easier to understand and work with.\n*   **Easier Debugging:** Isolating issues within a specific agent dramatically speeds up the debugging process.\n*   **Reduced Interdependencies:** Each agent can often be developed and tested with minimal reliance on others. This minimizes the dreaded \"ripple effect\" when changes are made, significantly reducing the risk of introducing new bugs and accelerating the overall development lifecycle.\n*   **Scalability by Design:** Adding new functionalities or handling increased loads often means introducing new agents or enhancing existing ones, rather than overhauling the entire system. This makes your software inherently more scalable and adaptable to future demands.\n\n### 2. Dynamic Problem Solving and Adaptability: Software That Thinks\n\nBeyond just structure, MAS imbues your software with genuine intelligence and responsiveness:\n\n*   **Intelligent Collaboration:** Agents can communicate, negotiate, and coordinate their actions to achieve a common goal. This collective intelligence enables them to tackle problems far more complex than any single program could handle effectively.\n*   **Autonomous Decision-Making:** Each agent can possess its own goals and make decisions based on its local knowledge and perception of the environment. This autonomy leads to more resilient and responsive systems that can react dynamically to changing conditions.\n*   **Learning and Evolution:** MAS can be designed to learn from experience and adapt their behavior over time. This powerful capability allows your software to continuously improve its performance and efficiency without constant manual intervention.\n\n### 3. Robustness and Resilience: Systems That Bounce Back\n\nOne of the most significant advantages of a distributed approach is enhanced reliability:\n\n*   **Fault Tolerance:** If one agent encounters an error or fails, the entire system doesn't necessarily collapse. Other agents can potentially compensate for the failed agent's role, or the system can gracefully degrade its functionality, ensuring continued operation.\n*   **Distributed Intelligence:** Spreading the workload and decision-making across multiple agents makes the system inherently less vulnerable to single points of failure. This is absolutely crucial for mission-critical applications where downtime is simply not an option.\n*   **Self-Healing Capabilities:** Advanced MAS architectures can even be programmed to detect and potentially repair internal issues, further enhancing their reliability and reducing the need for constant human oversight.\n\n### Conclusion: Embrace the Agent Revolution\n\nMulti-Agent Systems are not just a theoretical concept; they represent a powerful paradigm shift for software developers. By embracing MAS, you can build software solutions that are more modular, intelligent, and robust ‚Äì all while being easier to develop, maintain, and scale.\n\nAre you ready to empower your code with the collective intelligence of multiple agents and build the next generation of truly smart applications? The future of software is collaborative, and it's time you joined the agent revolution.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:47:01.708956Z","iopub.execute_input":"2025-11-13T20:47:01.709612Z","iopub.status.idle":"2025-11-13T20:47:01.714001Z","shell.execute_reply.started":"2025-11-13T20:47:01.709595Z","shell.execute_reply":"2025-11-13T20:47:01.713312Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:47:04.153812Z","iopub.execute_input":"2025-11-13T20:47:04.154153Z","iopub.status.idle":"2025-11-13T20:47:04.158658Z","shell.execute_reply.started":"2025-11-13T20:47:04.154131Z","shell.execute_reply":"2025-11-13T20:47:04.157884Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:47:06.578701Z","iopub.execute_input":"2025-11-13T20:47:06.578966Z","iopub.status.idle":"2025-11-13T20:47:06.583912Z","shell.execute_reply.started":"2025-11-13T20:47:06.578947Z","shell.execute_reply":"2025-11-13T20:47:06.582860Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:47:09.174734Z","iopub.execute_input":"2025-11-13T20:47:09.175019Z","iopub.status.idle":"2025-11-13T20:47:09.179687Z","shell.execute_reply.started":"2025-11-13T20:47:09.175003Z","shell.execute_reply":"2025-11-13T20:47:09.179053Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:47:11.886719Z","iopub.execute_input":"2025-11-13T20:47:11.887811Z","iopub.status.idle":"2025-11-13T20:47:11.891877Z","shell.execute_reply.started":"2025-11-13T20:47:11.887781Z","shell.execute_reply":"2025-11-13T20:47:11.891289Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:47:14.159246Z","iopub.execute_input":"2025-11-13T20:47:14.159489Z","iopub.status.idle":"2025-11-13T20:47:20.992960Z","shell.execute_reply.started":"2025-11-13T20:47:14.159474Z","shell.execute_reply":"2025-11-13T20:47:20.992122Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nFinanceResearcher > **Fintech Trends:**\n\n1.  **AI and ML Integration:** Artificial intelligence and machine learning are increasingly used for fraud detection, personalized services, and credit scoring, leading to smarter and more efficient financial interactions.\n2.  **Emerging Payment Technologies:** New payment methods, including stablecoins and real-time bank-to-bank transfers (e.g., FedNow), are gaining mainstream adoption, offering faster and more streamlined transactions.\n3.  **Open Banking Expansion:** Open Banking and Open Finance are extending to cover investments, pensions, and insurance, making payments more efficient and data sharing more comprehensive, though increasing competition and data security risks.\n\n**Market Implications:** These trends are driving significant market growth, with the global fintech market projected to reach $1.1 trillion by 2032. Increased efficiency, enhanced customer experiences, and greater financial inclusion are key market benefits, but also necessitate robust cybersecurity and evolving regulatory frameworks.\n\n**Future Outlook:** The fintech sector will continue its rapid innovation, driven by AI, blockchain, and evolving payment systems. Companies must remain agile to capitalize on opportunities and mitigate risks, with a strong emphasis on cybersecurity and regulatory compliance.\nTechResearcher > **AI/ML Trends Briefing**\n\nThe AI and Machine Learning landscape is rapidly evolving, with significant advancements poised to transform industries. Three key developments stand out:\n\n1.  **Generative AI Expansion:** This trend involves AI models creating diverse content like text, images, video, and music. Companies like OpenAI (with GPT models), Google (Imagen, Muse), and NVIDIA are at the forefront. Its impact spans content creation, design, and personalized user experiences.\n\n2.  **Explainable AI (XAI):** As AI adoption grows, transparency in decision-making is crucial, especially in sensitive sectors like healthcare and finance. XAI aims to make AI systems understandable and trustworthy. Key players include companies developing AI solutions for regulated industries. The impact is increased trust, compliance with regulations, and ethical AI deployment.\n\n3.  **AI-Powered Automation and Agentic AI:** AI is increasingly automating complex tasks and acting autonomously. This includes AI agents handling customer support, inventory, and predictive maintenance, as well as autonomous systems in logistics and transportation. Companies like Microsoft, Google, and NVIDIA are heavily involved. The impact is enhanced operational efficiency, reduced human error, and cost savings across various sectors.\n\nThe overarching impact of these trends is a significant boost in productivity, enhanced decision-making, and the creation of new opportunities across technology, health, and finance. However, challenges such as data privacy, ethical considerations, and workforce adaptation remain critical.\nHealthResearcher > Here's a brief executive summary of recent breakthroughs in Tech, Health, and Finance:\n\n**Health:**\n*   **AI-driven Diagnostics:** Artificial intelligence is increasingly used for early disease detection, showing remarkable accuracy in identifying cancers and predicting sepsis. This is expected to become widespread in clinical practice.\n*   **Advanced Vaccine Technology:** mRNA vaccine development has accelerated, and innovations like microneedle patches for vaccine delivery are poised to improve global access.\n*   **Therapeutics for Chronic Diseases:** New treatments are emerging to delay conditions like Type 1 diabetes and manage infectious diseases more effectively.\n\n**Technology:**\n*   **Agentic AI and Autonomous Systems:** AI is moving beyond simple tasks to \"virtual coworkers\" that can plan and execute complex workflows. Autonomous robots and digital agents are transitioning to practical applications across industries.\n*   **Quantum Computing:** Advancements are making quantum computing more accessible, with potential to revolutionize drug discovery, cryptography, and complex modeling. Practical business applications are emerging.\n*   **5G and Advanced Connectivity:** The expansion of 5G is enabling real-time communication for autonomous vehicles, smart cities, and remote healthcare.\n\n**Finance:**\n*   **Generative AI in Finance:** AI is enhancing personalized financial planning, wealth management, and automating processes like underwriting, with significant impact by 2025.\n*   **Blockchain and DeFi:** Blockchain continues to find new applications beyond cryptocurrency, including supply chain management and digital identity. Decentralized Finance (DeFi) is also gaining traction.\n*   **Enhanced Cybersecurity:** With increased digitalization, AI-driven predictive and proactive cybersecurity strategies are critical to combat evolving threats in financial services.\n\n**Estimated Timelines:**\n*   **Immediate to 2025:** Widespread adoption of AI in diagnostics, generative AI in financial services, and practical applications of 5G.\n*   **2025-2030:** Increased accessibility and application of quantum computing, broader integration of blockchain, and maturing autonomous systems.\n*   **Beyond 2030:** Continued evolution and deeper integration of these technologies, with potential for more transformative impacts.\nAggregatorAgent > ## Executive Summary: Daily Briefing - Tech, Health, and Finance\n\n**Key Takeaway:** The pervasive influence of Artificial Intelligence is the dominant theme across technology, health, and finance, driving significant advancements and presenting both immense opportunities and critical challenges.\n\n**Common Themes & Surprising Connections:**\n\n*   **AI as a Core Enabler:** AI, particularly **Generative AI** and **Agentic AI**, is revolutionizing content creation, automation, and personalized experiences in all three sectors. In finance, it's enhancing fraud detection and personalized services. In health, AI-driven diagnostics are improving early disease detection, while agentic AI acts as sophisticated \"virtual coworkers\" for complex workflows.\n*   **Data, Trust, and Security:** The increasing reliance on AI and expanded data sharing (e.g., Open Banking) highlights the paramount importance of **cybersecurity** and **Explainable AI (XAI)**. Trust and transparency are crucial, especially in regulated industries like finance and healthcare.\n*   **Accelerated Innovation:** Emerging technologies like **mRNA vaccines**, **quantum computing**, and **advanced connectivity (5G)** are converging with AI to unlock new possibilities, from drug discovery to remote healthcare and complex financial modeling.\n\n**Most Important Takeaways:**\n\n1.  **AI-driven transformation is accelerating:** Expect widespread adoption of AI in diagnostics and financial services in the immediate future, with increasingly autonomous systems becoming commonplace by 2025.\n2.  **Interdisciplinary impact:** Advancements in one sector rapidly influence others; for example, AI in healthcare diagnostics could eventually influence insurance risk assessment in finance.\n3.  **Ethical and security considerations are paramount:** As these technologies become more integrated, proactive measures for data privacy, ethical deployment, and robust cybersecurity are essential for realizing their full potential responsibly.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:48:11.570619Z","iopub.execute_input":"2025-11-13T20:48:11.571698Z","iopub.status.idle":"2025-11-13T20:48:11.576448Z","shell.execute_reply.started":"2025-11-13T20:48:11.571647Z","shell.execute_reply":"2025-11-13T20:48:11.575642Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:48:15.187422Z","iopub.execute_input":"2025-11-13T20:48:15.187678Z","iopub.status.idle":"2025-11-13T20:48:15.192222Z","shell.execute_reply.started":"2025-11-13T20:48:15.187662Z","shell.execute_reply":"2025-11-13T20:48:15.191471Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:48:18.547618Z","iopub.execute_input":"2025-11-13T20:48:18.547866Z","iopub.status.idle":"2025-11-13T20:48:18.553999Z","shell.execute_reply.started":"2025-11-13T20:48:18.547849Z","shell.execute_reply":"2025-11-13T20:48:18.552423Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:48:20.620440Z","iopub.execute_input":"2025-11-13T20:48:20.620699Z","iopub.status.idle":"2025-11-13T20:48:20.625855Z","shell.execute_reply.started":"2025-11-13T20:48:20.620682Z","shell.execute_reply":"2025-11-13T20:48:20.624997Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:48:22.926110Z","iopub.execute_input":"2025-11-13T20:48:22.926407Z","iopub.status.idle":"2025-11-13T20:48:22.932306Z","shell.execute_reply.started":"2025-11-13T20:48:22.926388Z","shell.execute_reply":"2025-11-13T20:48:22.931207Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:48:25.035678Z","iopub.execute_input":"2025-11-13T20:48:25.035934Z","iopub.status.idle":"2025-11-13T20:48:33.409714Z","shell.execute_reply.started":"2025-11-13T20:48:25.035898Z","shell.execute_reply":"2025-11-13T20:48:33.408936Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > The salt spray kissed Silas‚Äôs weathered face as he trimmed the lamp. For forty years, this lonely tower had been his world. Tonight, however, felt different. A storm brewed, a rare, silent one, with an unnerving stillness. As he moved a dusty chart to make room for a fresh log, his fingers brushed against something tucked behind the roll. It was a map, not of any coastline he knew, but of stars, rendered in a luminescence that pulsed with an inner light. Strange constellations, patterns never cataloged by man, shimmered on the vellum. A single, bold X marked a point in the swirling celestial sea. Silas, a man of routine, felt a tremor of something akin to wonder. The sea outside churned, mirroring the unknown depths now revealed in his hands.\nCriticAgent > This is a promising start with excellent atmosphere and a compelling hook! Here are a few suggestions for improvement:\n\n1.  **Deepen Silas's internal reaction:** While you mention a \"tremor of something akin to wonder,\" expanding on Silas's feelings would make him more relatable. What does a man of forty years of routine *truly* feel when faced with the utterly unknown? Is it fear, excitement, a profound sense of destiny, or a mix? Show, don't just tell, this internal shift. Perhaps his hands tremble more, or he forgets to trim the lamp for a moment.\n\n2.  **Enhance the map's description and implications:** The \"luminescence that pulsed with an inner light\" and \"strange constellations\" are intriguing. Consider adding a bit more sensory detail or hinting at what the map *might* represent. Does the light have a particular color? Does it feel warm or cool to the touch? Does Silas recognize any symbols, even if distorted from familiar ones, that might hint at its origin or purpose? This could also foreshadow the next steps in the story.\n\n3.  **Strengthen the connection between the storm and the map:** The \"rare, silent storm\" is an excellent touch. You state the sea \"churned, mirroring the unknown depths now revealed in his hands.\" To make this connection more impactful, consider weaving the storm's peculiarity more directly into Silas's discovery or the map itself. Does the storm's silence mirror the map's quiet luminescence? Does the \"unnerving stillness\" outside reflect the profound quietude of the cosmos depicted on the map?\nRefinerAgent > The salt spray kissed Silas‚Äôs weathered face as he trimmed the lamp, the familiar routine a decades-long anchor in his solitary life. For forty years, this lonely tower had been his world, its rhythmic beam a testament to his unwavering dedication. Tonight, however, a disquieting unfamiliarity clung to the air. A storm brewed, a rare, silent one, its approach marked not by the roar of wind and waves, but by an unnerving stillness that pressed in on the tower like a physical weight.\n\nAs Silas moved a dusty chart to make room for a fresh log, his gnarled fingers, accustomed to the rough textures of rope and brass, brushed against something unexpected, tucked behind the brittle roll. It was a map, ancient and strangely supple. But this was no chart of any coastline he knew, nor any sea that had ever churned beneath his lonely watch. It was a map of stars, rendered in a luminescence that pulsed with an inner, ethereal blue light, cool and silent against his skin. Strange constellations, patterns never cataloged by man, shimmered on the vellum, alien yet profoundly compelling. A single, bold X, stark against the swirling celestial sea, marked a point of impossible depth.\n\nA tremor, far more profound than mere wonder, coursed through Silas. His breath hitched, and for a heart-stopping moment, his hand, the one steadying the lamp, trembled. Forty years of predictable tides and charted skies had shaped him, and now, faced with this cosmic enigma, a dizzying cocktail of fear and an almost unbearable sense of destiny washed over him. His mind, usually as ordered as his lamp‚Äôs wick, reeled. Was this a message? A warning? Or an invitation? The silence outside, a mirror to the map‚Äôs own quiet radiance, seemed to deepen, as if the universe itself was holding its breath. The sea below, no longer a familiar adversary but a churning, dark reflection of the unknown depths now unfurled in his hands, seemed to whisper secrets in time with the map's faint, pulsing glow.\nCriticAgent > This is an excellent revision! You've taken the initial premise and infused it with a richer emotional landscape and more evocative imagery.\n\nYour suggestions have been successfully implemented, particularly the deepening of Silas's internal reaction and the enhanced description of the map and its implications. The connection between the silent storm and the map's quiet radiance is also more strongly felt.\n\nAPPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}